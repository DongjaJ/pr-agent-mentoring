# 📘 1주차 - 개인 학습 내용 정리

---

## 1. Git과 Pull Request

### 1.1 Git, Git Flow, GitHub Flow

- **Git**  
  분산 버전 관리 시스템. 코드 변경 이력을 효율적으로 관리 가능해 협업에 효과적.

- **Git Flow**  
  전통적인 브랜치 전략. 안정적인 릴리즈 프로세스, 복잡한 프로젝트에 적합.
  배포 방식: 릴리즈 주기 중심.
  브랜치 구성 예:
  - `main`: 배포 가능한 최종 버전
  - `develop`: 다음 릴리즈를 위한 개발 브랜치
  - `feature/`: 기능 단위 개발 브랜치 (ex. `feature/login`)
  - `release/`: 릴리즈 준비 브랜치
  - `hotfix/`: 운영 중 긴급 수정
  
- **GitHub Flow**  
  GitHub에서 주로 사용하는 간결한 브랜치 전략. 단순한 협업 플로우. PR 머지 후 바로 배포 가능. 지속적 배포(CD)에 적합.
  1. `main`에서 파생된 브랜치 생성 (ex. `feature/login`)
  2. 기능 구현 후 커밋 및 푸시
  3. Pull Request 생성하여 코드 리뷰 요청
  4. 리뷰 승인 후 `main`에 Merge
  5. Merge 후 자동 배포 가능

### 1.2 Pull Request

- **워크플로우**
  ```
  Fork/Clone → 브랜치 생성 → 커밋 → Push → PR 생성 → 리뷰/수정 → Merge
  ```

- **Best Practice**
  - PR은 **작고 명확한 단위로 나눠서** 제출
  - 제목은 명확하게, 본문에는 **목적과 변경사항** 간단히 요약
  - **Reviewer 지정** 및 피드백 반영 적극 수행

---
## 2. LLM (Large Language Model)

### 2.1 LLM 구조 및 작동 원리

- **LLM (Large Language Model)이란?**  
  대규모 텍스트 데이터를 기반으로 학습하여 인간처럼 자연어를 이해하고 생성할 수 있는 모델.  
  대표적으로 OpenAI의 GPT 시리즈, Google's Gemini, Meta의 LLaMA 등이 있음.

- **기반 구조: Transformer (Vaswani et al., 2017)**  
  기존 RNN, LSTM의 한계를 극복한 구조로, 병렬 처리가 가능하고 문맥 정보 반영에 강점을 가짐.

- **핵심 구성 요소**
  - **Tokenization**: 문장을 subword 단위로 나누어 숫자 토큰으로 변환
  - **Embedding**: 토큰을 고차원 벡터로 변환 (단어의 의미를 수치화)
  - **Positional Encoding**: 순서 정보를 주입하여 단어 간 관계를 학습할 수 있도록 함
  - **Multi-head Self-Attention**: 문장 내 모든 단어의 관계를 동시에 고려 (중요 단어에 가중치 부여)
  - **Feedforward Neural Network**: Attention 이후 각 위치에서 비선형 변환 수행
  - **Residual Connection + LayerNorm**: 안정적인 학습을 위한 보조 구조

- **동작 흐름**
  ```
  입력 문장 → Tokenize → Embedding + Positional Encoding →
  Transformer Encoder/Decoder Layer (Self-Attention + FFNN) →
  출력 토큰 예측 → 디코딩 후 자연어 출력
  ```

- **학습 방식**
  - **Pretraining**  
    - 대규모 범용 텍스트 데이터(웹, 논문, 뉴스 등)로 self-supervised learning  
    - 보통 다음 토큰 예측 또는 masked token 복원 방식
  - **Finetuning**  
    - 특정 작업(예: 요약, 번역, QA)에 맞춰 labeled dataset으로 추가 학습  
    - Task-specific 성능을 높이기 위한 단계

- **Inference**
  - 사용자가 Prompt를 입력하면, 모델이 사전 학습된 패턴을 바탕으로 응답을 생성  
  - Greedy, Top-k, Top-p, Temperature 등 다양한 디코딩 전략 존재

---

### 2.2 Prompt Engineering

- **Prompt란?**  
  LLM에게 특정 작업을 시키기 위해 입력하는 문장(지시문).  
  같은 모델이라도 prompt 작성 방식에 따라 응답 품질이 크게 달라짐.

- **Prompt Engineering의 중요성**
  - Finetuning 없이 다양한 작업을 수행 가능하게 함
  - LLM을 다루는 핵심 기술 중 하나로, 서비스 응답 품질에 직접적인 영향

- **기법 유형**

  1. **Zero-shot prompting**
     - 예시 없이 직접 지시  
     - ex) `"이 문장을 영어로 번역해줘: 나는 학교에 간다"`

  2. **Few-shot prompting**
     - 예시 몇 개와 함께 지시  
     - ex)  
       ```
       Q: 서울은 어느 나라에 있나요?  
       A: 한국에 있습니다.  
       Q: 도쿄는 어느 나라에 있나요?  
       A: 일본에 있습니다.  
       Q: 베를린은 어느 나라에 있나요?  
       A:
       ```

  3. **Chain-of-Thought (CoT) prompting**
     - 모델이 단계적으로 사고하게 유도하여 복잡한 reasoning 문제 해결 능력 향상  
     - ex) `"답을 구하기 전에 생각하는 과정을 단계별로 써줘"`

  4. **Instruction prompting**
     - 명시적으로 역할과 출력을 지시  
     - ex) `"너는 법률 전문가야. 아래 계약서 문장을 쉽게 설명해줘."`

- **Best Practice**
  - **역할 부여**: `"너는 의사야"`, `"너는 고객센터 상담원이야"`
  - **형식 지정**: `"표 형식으로 정리해줘"`, `"Markdown으로 작성해줘"`
  - **출력 제약**: `"세 문장 이내로 요약해줘"`, `"한글로 대답해줘"`

- **고급 전략 (optional)**
  - **Prompt Chaining**: 여러 프롬프트를 순차적으로 연결하여 고도화된 작업 수행
  - **Self-consistency decoding**: 다양한 reasoning 경로를 탐색하고 가장 일관된 결과 선택


※ 최근에는 Prompt Engineering을 자동화하거나 최적화하기 위한 연구도 활발하게 진행 중 (ex. AutoPrompt, Prompt Tuning, In-Context Learning 등)
